{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:10:38.538774Z","iopub.execute_input":"2025-07-05T16:10:38.539161Z","iopub.status.idle":"2025-07-05T16:10:38.824548Z","shell.execute_reply.started":"2025-07-05T16:10:38.539142Z","shell.execute_reply":"2025-07-05T16:10:38.823729Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_inference_server.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_gateway.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/__init__.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/relay.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/__init__.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom scipy.stats import skew,kurtosis,iqr\n\n#Deep Learning Libraries\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Dense,Dropout\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:10:44.440352Z","iopub.execute_input":"2025-07-05T16:10:44.440636Z","iopub.status.idle":"2025-07-05T16:10:57.580262Z","shell.execute_reply.started":"2025-07-05T16:10:44.440605Z","shell.execute_reply":"2025-07-05T16:10:57.579701Z"}},"outputs":[{"name":"stderr","text":"2025-07-05 16:10:46.372141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751731846.540011      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751731846.587881      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"target_behaviors = ['bfrb_type_A', 'bfrb_type_B']\n\n\nIMU_SENSOR_COLUMNS = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z', 'mag_x', 'mag_y', 'mag_z']\nTHERMOPILE_SENSOR_COLUMNS = ['therm_1', 'therm_2', 'therm_3', 'therm_4']\nTOF_SENSOR_COLUMNS = ['tof_distance', 'tof_signal_strength'] \n\nALL_EXPECTED_SENSOR_COLUMNS = IMU_SENSOR_COLUMNS + THERMOPILE_SENSOR_COLUMNS + TOF_SENSOR_COLUMNS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:11:02.720007Z","iopub.execute_input":"2025-07-05T16:11:02.721011Z","iopub.status.idle":"2025-07-05T16:11:02.725058Z","shell.execute_reply.started":"2025-07-05T16:11:02.720985Z","shell.execute_reply":"2025-07-05T16:11:02.724415Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:11:06.593915Z","iopub.execute_input":"2025-07-05T16:11:06.594214Z","iopub.status.idle":"2025-07-05T16:11:37.399315Z","shell.execute_reply.started":"2025-07-05T16:11:06.594192Z","shell.execute_reply":"2025-07-05T16:11:37.398715Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.columns[1:50]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:11:42.106107Z","iopub.execute_input":"2025-07-05T16:11:42.106885Z","iopub.status.idle":"2025-07-05T16:11:42.113903Z","shell.execute_reply.started":"2025-07-05T16:11:42.106858Z","shell.execute_reply":"2025-07-05T16:11:42.113146Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['sequence_type', 'sequence_id', 'sequence_counter', 'subject',\n       'orientation', 'behavior', 'phase', 'gesture', 'acc_x', 'acc_y',\n       'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3',\n       'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3',\n       'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9',\n       'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14',\n       'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19',\n       'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24',\n       'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28'],\n      dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Loading Sensor Data","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv'\n\ntry:\n    df=pd.read_csv(data_path)\n    core_required_columns=['timestamp','behavior']+[col for col in IMU_SENSOR_COLUMNS if col in df.columns]\n    if not all(col in df.columns for col in core_required_columns):\n        print(f\"Warning: Missing some core IMU columns or 'timestamp'/'behavior'. Please check your CSV header.\")\n        print(f\"Expected: {core_required_columns} + any thermopile/ToF columns\")\n\n    print(f\"Data loaded successfully from:{data_path}\")\n    print(\"Sample Data Head:\")\n    print(df.head())\n    print(f\"Total number of samples: {len(df)}\")\n    print(f\"Columns found in data:{df.columns.tolist()}\")\n    print(\"\\n\")\n\nexcept FileNotFoundError:\n    print(f\"Error:Data file not found at '{data_path}'.\")\n    exit()\nexcept Exception as e:\n    print(f\"An unexpected error occured while loading data:{e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:11:47.627287Z","iopub.execute_input":"2025-07-05T16:11:47.628031Z","iopub.status.idle":"2025-07-05T16:12:06.035722Z","shell.execute_reply.started":"2025-07-05T16:11:47.628003Z","shell.execute_reply":"2025-07-05T16:12:06.034990Z"}},"outputs":[{"name":"stdout","text":"Warning: Missing some core IMU columns or 'timestamp'/'behavior'. Please check your CSV header.\nExpected: ['timestamp', 'behavior', 'acc_x', 'acc_y', 'acc_z'] + any thermopile/ToF columns\nData loaded successfully from:/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\nSample Data Head:\n              row_id sequence_type sequence_id  sequence_counter      subject  \\\n0  SEQ_000007_000000        Target  SEQ_000007                 0  SUBJ_059520   \n1  SEQ_000007_000001        Target  SEQ_000007                 1  SUBJ_059520   \n2  SEQ_000007_000002        Target  SEQ_000007                 2  SUBJ_059520   \n3  SEQ_000007_000003        Target  SEQ_000007                 3  SUBJ_059520   \n4  SEQ_000007_000004        Target  SEQ_000007                 4  SUBJ_059520   \n\n                       orientation                                   behavior  \\\n0  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n1  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n2  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n3  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n4  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n\n        phase             gesture     acc_x  ...  tof_5_v54  tof_5_v55  \\\n0  Transition  Cheek - pinch skin  6.683594  ...       -1.0       -1.0   \n1  Transition  Cheek - pinch skin  6.949219  ...       -1.0       -1.0   \n2  Transition  Cheek - pinch skin  5.722656  ...       -1.0       -1.0   \n3  Transition  Cheek - pinch skin  6.601562  ...       -1.0       -1.0   \n4  Transition  Cheek - pinch skin  5.566406  ...       -1.0       -1.0   \n\n   tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  \\\n0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n2      112.0      119.0       -1.0       -1.0       -1.0       -1.0   \n3      101.0      111.0       -1.0       -1.0       -1.0       -1.0   \n4      101.0      109.0      125.0       -1.0       -1.0       -1.0   \n\n   tof_5_v62  tof_5_v63  \n0       -1.0       -1.0  \n1       -1.0       -1.0  \n2       -1.0       -1.0  \n3       -1.0       -1.0  \n4       -1.0       -1.0  \n\n[5 rows x 341 columns]\nTotal number of samples: 574945\nColumns found in data:['row_id', 'sequence_type', 'sequence_id', 'sequence_counter', 'subject', 'orientation', 'behavior', 'phase', 'gesture', 'acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5', 'tof_1_v0', 'tof_1_v1', 'tof_1_v2', 'tof_1_v3', 'tof_1_v4', 'tof_1_v5', 'tof_1_v6', 'tof_1_v7', 'tof_1_v8', 'tof_1_v9', 'tof_1_v10', 'tof_1_v11', 'tof_1_v12', 'tof_1_v13', 'tof_1_v14', 'tof_1_v15', 'tof_1_v16', 'tof_1_v17', 'tof_1_v18', 'tof_1_v19', 'tof_1_v20', 'tof_1_v21', 'tof_1_v22', 'tof_1_v23', 'tof_1_v24', 'tof_1_v25', 'tof_1_v26', 'tof_1_v27', 'tof_1_v28', 'tof_1_v29', 'tof_1_v30', 'tof_1_v31', 'tof_1_v32', 'tof_1_v33', 'tof_1_v34', 'tof_1_v35', 'tof_1_v36', 'tof_1_v37', 'tof_1_v38', 'tof_1_v39', 'tof_1_v40', 'tof_1_v41', 'tof_1_v42', 'tof_1_v43', 'tof_1_v44', 'tof_1_v45', 'tof_1_v46', 'tof_1_v47', 'tof_1_v48', 'tof_1_v49', 'tof_1_v50', 'tof_1_v51', 'tof_1_v52', 'tof_1_v53', 'tof_1_v54', 'tof_1_v55', 'tof_1_v56', 'tof_1_v57', 'tof_1_v58', 'tof_1_v59', 'tof_1_v60', 'tof_1_v61', 'tof_1_v62', 'tof_1_v63', 'tof_2_v0', 'tof_2_v1', 'tof_2_v2', 'tof_2_v3', 'tof_2_v4', 'tof_2_v5', 'tof_2_v6', 'tof_2_v7', 'tof_2_v8', 'tof_2_v9', 'tof_2_v10', 'tof_2_v11', 'tof_2_v12', 'tof_2_v13', 'tof_2_v14', 'tof_2_v15', 'tof_2_v16', 'tof_2_v17', 'tof_2_v18', 'tof_2_v19', 'tof_2_v20', 'tof_2_v21', 'tof_2_v22', 'tof_2_v23', 'tof_2_v24', 'tof_2_v25', 'tof_2_v26', 'tof_2_v27', 'tof_2_v28', 'tof_2_v29', 'tof_2_v30', 'tof_2_v31', 'tof_2_v32', 'tof_2_v33', 'tof_2_v34', 'tof_2_v35', 'tof_2_v36', 'tof_2_v37', 'tof_2_v38', 'tof_2_v39', 'tof_2_v40', 'tof_2_v41', 'tof_2_v42', 'tof_2_v43', 'tof_2_v44', 'tof_2_v45', 'tof_2_v46', 'tof_2_v47', 'tof_2_v48', 'tof_2_v49', 'tof_2_v50', 'tof_2_v51', 'tof_2_v52', 'tof_2_v53', 'tof_2_v54', 'tof_2_v55', 'tof_2_v56', 'tof_2_v57', 'tof_2_v58', 'tof_2_v59', 'tof_2_v60', 'tof_2_v61', 'tof_2_v62', 'tof_2_v63', 'tof_3_v0', 'tof_3_v1', 'tof_3_v2', 'tof_3_v3', 'tof_3_v4', 'tof_3_v5', 'tof_3_v6', 'tof_3_v7', 'tof_3_v8', 'tof_3_v9', 'tof_3_v10', 'tof_3_v11', 'tof_3_v12', 'tof_3_v13', 'tof_3_v14', 'tof_3_v15', 'tof_3_v16', 'tof_3_v17', 'tof_3_v18', 'tof_3_v19', 'tof_3_v20', 'tof_3_v21', 'tof_3_v22', 'tof_3_v23', 'tof_3_v24', 'tof_3_v25', 'tof_3_v26', 'tof_3_v27', 'tof_3_v28', 'tof_3_v29', 'tof_3_v30', 'tof_3_v31', 'tof_3_v32', 'tof_3_v33', 'tof_3_v34', 'tof_3_v35', 'tof_3_v36', 'tof_3_v37', 'tof_3_v38', 'tof_3_v39', 'tof_3_v40', 'tof_3_v41', 'tof_3_v42', 'tof_3_v43', 'tof_3_v44', 'tof_3_v45', 'tof_3_v46', 'tof_3_v47', 'tof_3_v48', 'tof_3_v49', 'tof_3_v50', 'tof_3_v51', 'tof_3_v52', 'tof_3_v53', 'tof_3_v54', 'tof_3_v55', 'tof_3_v56', 'tof_3_v57', 'tof_3_v58', 'tof_3_v59', 'tof_3_v60', 'tof_3_v61', 'tof_3_v62', 'tof_3_v63', 'tof_4_v0', 'tof_4_v1', 'tof_4_v2', 'tof_4_v3', 'tof_4_v4', 'tof_4_v5', 'tof_4_v6', 'tof_4_v7', 'tof_4_v8', 'tof_4_v9', 'tof_4_v10', 'tof_4_v11', 'tof_4_v12', 'tof_4_v13', 'tof_4_v14', 'tof_4_v15', 'tof_4_v16', 'tof_4_v17', 'tof_4_v18', 'tof_4_v19', 'tof_4_v20', 'tof_4_v21', 'tof_4_v22', 'tof_4_v23', 'tof_4_v24', 'tof_4_v25', 'tof_4_v26', 'tof_4_v27', 'tof_4_v28', 'tof_4_v29', 'tof_4_v30', 'tof_4_v31', 'tof_4_v32', 'tof_4_v33', 'tof_4_v34', 'tof_4_v35', 'tof_4_v36', 'tof_4_v37', 'tof_4_v38', 'tof_4_v39', 'tof_4_v40', 'tof_4_v41', 'tof_4_v42', 'tof_4_v43', 'tof_4_v44', 'tof_4_v45', 'tof_4_v46', 'tof_4_v47', 'tof_4_v48', 'tof_4_v49', 'tof_4_v50', 'tof_4_v51', 'tof_4_v52', 'tof_4_v53', 'tof_4_v54', 'tof_4_v55', 'tof_4_v56', 'tof_4_v57', 'tof_4_v58', 'tof_4_v59', 'tof_4_v60', 'tof_4_v61', 'tof_4_v62', 'tof_4_v63', 'tof_5_v0', 'tof_5_v1', 'tof_5_v2', 'tof_5_v3', 'tof_5_v4', 'tof_5_v5', 'tof_5_v6', 'tof_5_v7', 'tof_5_v8', 'tof_5_v9', 'tof_5_v10', 'tof_5_v11', 'tof_5_v12', 'tof_5_v13', 'tof_5_v14', 'tof_5_v15', 'tof_5_v16', 'tof_5_v17', 'tof_5_v18', 'tof_5_v19', 'tof_5_v20', 'tof_5_v21', 'tof_5_v22', 'tof_5_v23', 'tof_5_v24', 'tof_5_v25', 'tof_5_v26', 'tof_5_v27', 'tof_5_v28', 'tof_5_v29', 'tof_5_v30', 'tof_5_v31', 'tof_5_v32', 'tof_5_v33', 'tof_5_v34', 'tof_5_v35', 'tof_5_v36', 'tof_5_v37', 'tof_5_v38', 'tof_5_v39', 'tof_5_v40', 'tof_5_v41', 'tof_5_v42', 'tof_5_v43', 'tof_5_v44', 'tof_5_v45', 'tof_5_v46', 'tof_5_v47', 'tof_5_v48', 'tof_5_v49', 'tof_5_v50', 'tof_5_v51', 'tof_5_v52', 'tof_5_v53', 'tof_5_v54', 'tof_5_v55', 'tof_5_v56', 'tof_5_v57', 'tof_5_v58', 'tof_5_v59', 'tof_5_v60', 'tof_5_v61', 'tof_5_v62', 'tof_5_v63']\n\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"The purpose of this code is to convert raw time-series sensor data into a structured format suitable for training a machine learning model. This involves splitting the data into manageable parts, extracting informative statistics, and preparing labeled inputs.\n\n1. Sliding Window with Overlap\n\nThe time-series data is divided into windows of fixed length (e.g., 50 rows), with partial overlap (e.g., 25 rows). This sliding window approach ensures that short-term patterns in the data are captured multiple times and prevents information loss that could occur at the boundaries of non-overlapping windows.\n\n2. Filtering Valid Windows\n\nOnly windows where all rows have the same behavior label are retained. This is important for supervised learning tasks because mixed-label windows would confuse the model and reduce classification accuracy.\n\n\n3. Feature Extraction\n\nFor each window and each expected sensor column, 12 statistical features are computed:\n\nMean\n\nStandard deviation\n\nMinimum and maximum\n\nMedian and variance\n\nRoot mean square (RMS)\n\nSum of absolute values (SMA)\n\nPeak-to-peak (range)\n\nInterquartile range (IQR)\n\nSkewness\n\nKurtosis\n\n4. Handling Missing Data\n\nIf a particular sensor column is missing from the data, the code fills in a vector of twelve zeroes in its place. This maintains a consistent feature vector length for each window, which is critical for downstream model training.\n\n5. Validation and Collection\n\nEach extracted feature vector is checked to ensure it matches the expected total dimension. Valid vectors are added to the features list, their associated labels are added to labels, and the starting index of the window is recorded in window_indices.\n\nOnce all windows are processed, the collected data is converted into NumPy arrays:\n\nX: a 2D array of shape (num_windows, num_features) containing the feature vectors.\n\ny: a 1D array containing the label for each window.\n\nwindow_ids: a 1D array containing the starting index of each window.\n\n\n\n1.Most machine learning algorithms require fixed-length numerical inputs. This pipeline transforms variable-length time-series data into a structured, tabular format.\n\n2.Windowing allows you to isolate and capture short-term patterns in time-series signals, which is important for detecting behaviors or states that change over time.\n\n3.Overlapping windows increase the amount of training data and help capture transitions more effectively. Ensuring each window has a consistent label improves model clarity and prevents noisy supervision.","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"window_size=50 #Number of data points in each window\noverlap=25 #Number of overlapping data points between consecutive windows\n\nfeatures=[] # Extracted features for each window\nlabels=[] #Corresponding label for each window\nwindow_indices=[] #Starting index of each valid window\n\n# Helper function to extract statistical features for a single sensor series\ndef extract_sensor_features(series):\n    if series.empty:\n        # Return zeros for all features if series is empty (e.g., sensor not present)\n        # This list must match the number of features extracted per sensor type below\n        return [0.0] * 12 # 12 features per sensor (mean, std, min, max, median, var, rms, sma, ptp, iqr, skew, kurt)\n    return [\n        series.mean(), series.std(), series.min(), series.max(),\n        series.median(), series.var(), np.sqrt(np.mean(series**2)),\n        series.abs().sum(), np.ptp(series), iqr(series),\n        skew(series), kurtosis(series)\n    ]\n        \n    \nTOTAL_FEATURE_DIMENSION = len(ALL_EXPECTED_SENSOR_COLUMNS)*12\n\n\n#Sliding window loop\n\nfor i in range(0,len(df) - window_size,window_size - overlap):\n    window=df.iloc[i: i + window_size]\n\n\n    #Checking if window has enough data points and a consistent label\n    if len(window) == window_size and window['behavior'].nunique()==1: \n        \n        current_window_features=[]\n        for col in ALL_EXPECTED_SENSOR_COLUMNS:\n            \n            if col in window.columns:\n                current_window_features.extend(extract_sensor_features(window[col]))\n            else:\n                current_window_features.extend([0.0] * 12) #If a sensor is missing from data\n                \n        if len(current_window_features)==TOTAL_FEATURE_DIMENSION:\n            features.append(current_window_features)\n            labels.append(window['behavior'].iloc[0])\n            window_indices.append(i) # Store the starting index of the window\n                \n        else:print(f\"Warning: Feature dimension mismatch at window {i}. Expected {TOTAL_FEATURE_DIMENSION}, got {len(current_window_features)}. Skipping.\")\n\nif not features:\n    print(\"No features extracted. Please ensure your data is large enough for the chosen window size and overlap.\")\n    exit()\n\nX = np.array(features)  #shape: (num_windows,feature_size)\ny = np.array(labels)    #shape:(num_windows,)\nwindow_ids = np.array(window_indices)\n\nprint(f\"Extracted {X.shape[0]} windows with {X.shape[1]} features each.\")\nprint(f\"Labels shape: {y.shape}\")\nprint(\"\\n\")\n    \n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:13:02.606097Z","iopub.execute_input":"2025-07-05T16:13:02.606390Z","iopub.status.idle":"2025-07-05T16:13:13.385359Z","shell.execute_reply.started":"2025-07-05T16:13:02.606368Z","shell.execute_reply":"2025-07-05T16:13:13.384724Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3009994272.py:18: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n  skew(series), kurtosis(series)\n","output_type":"stream"},{"name":"stdout","text":"Extracted 1484 windows with 180 features each.\nLabels shape: (1484,)\n\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Encode Labels and Split Data","metadata":{}},{"cell_type":"markdown","source":"This code block is a critical stage in preparing labeled time-series data for training a machine learning model, specifically for behavior classification tasks using sensor data. It begins by validating the label array y to ensure it's a proper, non-empty NumPy array. This check is essential because a malformed or missing label array would break the entire modeling pipeline and lead to silent failures or misleading results. After confirming the validity of y, the code uses LabelEncoder to convert the original categorical behavior labels (like \"walking\", \"running\", \"jumping\") into integer class values (0, 1, 2, etc.). This numeric representation is required because most machine learning models cannot process string labels directly. Following this, the integer labels are passed to to_categorical, which transforms them into one-hot encoded vectors. This is crucial for classification models (especially neural networks) that use softmax outputs and categorical cross-entropy loss, as it ensures the true label is expressed as a vector with a 1 in the correct class position and 0s elsewhere.\n\nNext, the code calculates the number of unique classes and validates whether the dataset is large and diverse enough to proceed. It explicitly checks that there are at least two distinct classes and more than one sample. This is a safety step: training on too little data or with only one class would make the model useless, or worse, allow it to overfit with no generalization power. Once the data passes these checks, the code calls train_test_split to divide the dataset into training and testing sets using a 70-30 split (test_size=0.3). It also passes in window_ids, which represent the original positions of each windowed segment in the full dataset. This can be used later to map model predictions back to time indices for visualization or analysis.\n\nThe most important design decision here is the use of stratify=y_encoded. This ensures that each class is represented proportionally in both the training and testing datasets. Without stratification, random splitting might accidentally produce a test set that has too many examples of one class and too few (or none) of another, especially if the dataset is imbalanced. Such imbalance would distort evaluation metrics like accuracy, making the model appear better than it is. Finally, the code prints the shapes of the resulting splits (X_train, X_test, y_train, y_test) to verify that the data has been split correctly and remains aligned across features, labels, and window indices. All of these steps, combined with comprehensive error handling, ensure that the model is trained and evaluated on clean, balanced, and properly structured data.\n\n","metadata":{}},{"cell_type":"code","source":"try:\n    if not isinstance(y, np.ndarray) or y.size == 0:\n        print(\"Error: 'y' (labels) is not a valid numpy array or is empty when trying to encode. Check data loading and feature engineering steps.\")\n        exit()\n\n    label_encoder = LabelEncoder()\n    y_encoded = label_encoder.fit_transform(y)\n    num_classes = len(label_encoder.classes_)\n    print(f\"Detected {num_classes} behavior classes: {label_encoder.classes_}\")\n\n    y_categorical = to_categorical(y_encoded, num_classes=num_classes)  #One-Hot Encoding\n\n    if len(X) < 2 or num_classes < 2:\n        print(\"Not enough samples or unique classes to split data. Need at least 2 samples and 2 unique classes.\")\n        print(\"Consider adjusting window_size/overlap or providing more data with varied behaviors.\")\n        exit()\n\n    X_train, X_test, y_train, y_test, window_ids_train, window_ids_test = train_test_split(\n        X, y_categorical, window_ids, test_size=0.3, random_state=42, stratify=y_encoded\n    )\n\n    print(f\"Training features shape: {X_train.shape}\")\n    print(f\"Testing features shape: {X_test.shape}\")\n    print(f\"Training labels shape: {y_train.shape}\")\n    print(f\"Testing labels shape: {y_test.shape}\")\n    print(f\"Testing window IDs shape: {window_ids_test.shape}\")\n    print(\"\\n\")\n\nexcept NameError:\n    print(\"Critical Error: 'y' is not defined before starting label encoding. This indicates an issue in the preceding 'Feature Engineering' section or data loading, or an unstable environment.\")\n    print(\"Please ensure that your dataset exists, contains sufficient data, and has a 'behavior' column for labels.\")\n    exit()\n\nexcept Exception as e:\n    print(f\"An unexpected error occurred during label encoding or data splitting: {e}\")\n    exit()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:13:34.659329Z","iopub.execute_input":"2025-07-05T16:13:34.659613Z","iopub.status.idle":"2025-07-05T16:13:34.670142Z","shell.execute_reply.started":"2025-07-05T16:13:34.659592Z","shell.execute_reply":"2025-07-05T16:13:34.669349Z"}},"outputs":[{"name":"stdout","text":"Detected 4 behavior classes: ['Hand at target location' 'Moves hand to target location'\n 'Performs gesture' 'Relaxes and moves hand to target location']\nTraining features shape: (1038, 180)\nTesting features shape: (446, 180)\nTraining labels shape: (1038, 4)\nTesting labels shape: (446, 4)\nTesting window IDs shape: (446,)\n\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Feature Scaling","metadata":{}},{"cell_type":"markdown","source":"Feature scaling is a crucial preprocessing step, especially when working with models like LSTMs (Long Short-Term Memory networks), which are sensitive to the magnitude and range of input values. In the given code, StandardScaler() is used to normalize the feature sets by removing the mean and scaling to unit variance. This is important because LSTMs rely on gradient-based optimization and internal gating mechanisms (like sigmoid and tanh activations) that can become unstable or ineffective when input values vary widely in scale. If one feature has values in the range of thousands while another varies only between 0 and 1, the larger feature can disproportionately influence weight updates, making training inefficient or unstable. Scaling all features to a similar range ensures that each contributes equally and the learning process converges more reliably.\n\nThe methods fit_transform() and transform() are both part of how StandardScaler (and most Scikit-learn transformers) operate. fit_transform() does two things: it first learns the parameters from the data (in this case, the mean and standard deviation of each feature) and then uses those parameters to scale the data. This is appropriate for the training set because we want the model to learn the statistics of the data it will train on. On the other hand, transform() simply applies those already-learned parameters to new data, such as the test set, ensuring that it is scaled using the same mean and standard deviation as the training data. This is critical to avoid data leakage — the situation where information from the test set influences the model during training, leading to over-optimistic performance estimates.. Correctly applying scaling not only improves model convergence and performance but also ensures the integrity of the evaluation process.\n\n","metadata":{}},{"cell_type":"code","source":"scaler=StandardScaler()\nX_train_scaled=scaler.fit_transform(X_train)\nX_test_scaled=scaler.transform(X_test)\nprint(\"Features scaled.\")\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:14:02.004881Z","iopub.execute_input":"2025-07-05T16:14:02.005422Z","iopub.status.idle":"2025-07-05T16:14:02.031589Z","shell.execute_reply.started":"2025-07-05T16:14:02.005395Z","shell.execute_reply":"2025-07-05T16:14:02.030732Z"}},"outputs":[{"name":"stdout","text":"Features scaled.\n\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Reshape Data for LSTM Input","metadata":{}},{"cell_type":"markdown","source":"Reshaping the feature data is necessary to prepare it for input into an LSTM model, which requires data in a 3D format: `(samples, timesteps, features)`. In the below code, the data is reshaped so that each sample contains `1` timestep and a fixed number of features (e.g., 96), resulting in shapes like `(num_samples, 1, num_features)`. This format tells the LSTM to treat each sample as a single moment in time with multiple sensor-derived statistics. Although `timesteps = 1` doesn't allow the model to learn temporal patterns across multiple time steps, it ensures compatibility with the LSTM layer. To fully leverage LSTM’s ability to capture time-based dependencies, one would use `timesteps > 1`, where each sample represents a sequence of consecutive readings over time, enabling the model to learn how features evolve across multiple points in time.\n","metadata":{}},{"cell_type":"code","source":"timesteps=1\ninput_features=X_train_scaled.shape[1]\n\nX_train_reshaped=X_train_scaled.reshape(X_train_scaled.shape[0],timesteps,input_features)\n\nX_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], timesteps, input_features)\n\nprint(f\"Reshaped training features shape: {X_train_reshaped.shape}\")\nprint(f\"Reshaped testing features shape: {X_test_reshaped.shape}\")\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:14:10.369964Z","iopub.execute_input":"2025-07-05T16:14:10.370204Z","iopub.status.idle":"2025-07-05T16:14:10.375124Z","shell.execute_reply.started":"2025-07-05T16:14:10.370187Z","shell.execute_reply":"2025-07-05T16:14:10.374404Z"}},"outputs":[{"name":"stdout","text":"Reshaped training features shape: (1038, 1, 180)\nReshaped testing features shape: (446, 1, 180)\n\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"| **Component**        | **Parameter / Setting**                   | **Purpose**                                         | **Reasoning**                                                                                                                                     |\n| -------------------- | ----------------------------------------- | --------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **LSTM Layer**       | `units=100`                               | Number of memory cells (neurons)                    | Controls model capacity to learn complex patterns in sequences; 100 is a common starting point.                                                   |\n|                      | `input_shape=(timesteps, input_features)` | Shape of one input sample                           | Required in the first layer to define the structure: `timesteps` is the sequence length, `input_features` is the number of features per timestep. |\n|                      | `activation='relu'`                       | Activation function applied to outputs              | Speeds up training and avoids vanishing gradients; although `tanh` is traditional, `relu` can work well for preprocessed inputs.                  |\n| **Dropout Layer**    | `rate=0.2` (i.e., 20%)                    | Randomly disables neurons during training           | Prevents overfitting by forcing the model to not rely too heavily on any one neuron.                                                              |\n| **Dense Layer**      | `units=num_classes`                       | Number of output classes                            | Produces one output per class label; used for classification.                                                                                     |\n|                      | `activation='softmax'`                    | Converts logits to probabilities                    | Ensures output is interpretable as class probabilities; required for categorical classification.                                                  |\n| **Compile Step**     | `optimizer='adam'`                        | Optimization algorithm                              | Adapts learning rate, handles sparse gradients, and is efficient for many types of problems.                                                      |\n|                      | `loss='categorical_crossentropy'`         | Loss function for training                          | Appropriate for multi-class classification with one-hot encoded labels.                                                                           |\n|                      | `metrics=['accuracy']`                    | Evaluation metric                                   | Tracks percentage of correct predictions; commonly used for classification tasks.                                                                 |\n| **Training (`fit`)** | `X_train_reshaped`, `y_train`             | Input data and one-hot encoded labels               | Properly formatted data for LSTM training.                                                                                                        |\n|                      | `epochs=50`                               | Number of complete training passes through the data | More epochs give the model more time to learn; 50 is typical, but needs tuning based on validation results.                                       |\n|                      | `batch_size=32`                           | Number of samples per gradient update               | Smaller batches generalize better but train slower; 32 is a balanced default choice.                                                              |\n|                      | `validation_split=0.1`                    | Percentage of training data used for validation     | Helps monitor performance on unseen data during training; 10% is a common choice.                                                                 |\n|                      | `verbose=1`                               | Output display setting                              | Shows real-time progress bar and metrics per epoch during training.                                                                               |\n","metadata":{}},{"cell_type":"code","source":"model=Sequential()\nmodel.add(LSTM(units=100,input_shape=(timesteps,input_features),activation='relu'))# Add an LSTM layer with 100 memory units\n\n# Add dropout to prevent overfitting — randomly disables 20% of the LSTM's output units\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=num_classes,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nhistory=model.fit(\n    X_train_reshaped,y_train,\n    epochs=50,\n    batch_size=32,\n    validation_split=0.1,\n    verbose=1\n)\n\nprint(\"\\nModel training complete.\")\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:16:15.615230Z","iopub.execute_input":"2025-07-05T16:16:15.615504Z","iopub.status.idle":"2025-07-05T16:16:27.678258Z","shell.execute_reply.started":"2025-07-05T16:16:15.615484Z","shell.execute_reply":"2025-07-05T16:16:27.677704Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.6242 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 2/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0113 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 3/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0064 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 4/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0096 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 5/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0123 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 6/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0082 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 7/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0111 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 8/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0145 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 9/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0128 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 10/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0132 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 11/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0094 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 12/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0134 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 13/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0114 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 14/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0071 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 15/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0054 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 16/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0086 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 17/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0099 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 18/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0054 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 19/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0110 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 20/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0057 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 21/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0182 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 22/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0118 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 23/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0149 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 24/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0108 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 25/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0101 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 26/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0170 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 27/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0090 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 28/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0094 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 29/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0107 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 30/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0122 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 31/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0044 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 32/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0129 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 33/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0124 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 34/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0141 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 35/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0111 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 36/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0121 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 37/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0087 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 38/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0131 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 39/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0106 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 40/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0101 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 41/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0167 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 42/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0160 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 43/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0189 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 44/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0059 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 45/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0080 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 46/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0080 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 47/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0092 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 48/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0052 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 49/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0100 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\nEpoch 50/50\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0152 - loss: nan - val_accuracy: 0.0192 - val_loss: nan\n\nModel training complete.\n\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"The classification_report from sklearn.metrics provides a detailed breakdown of a classification model's performance across each class. It includes key evaluation metrics that help you understand how well the model is predicting each class — not just overall accuracy.\n\n| **Metric**    | **What it Measures**                                                        | **Why It’s Useful**                                                                                  |\n| ------------- | --------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n| **Precision** | Out of all predicted instances of a class, how many were actually correct?  | Helps understand how many false positives the model is making. High precision = fewer false alarms.  |\n| **Recall**    | Out of all actual instances of a class, how many were correctly predicted?  | Indicates how well the model captures all relevant cases (true positives). High recall = few misses. |\n| **F1-score**  | Harmonic mean of precision and recall. Balances the two in a single metric. | Useful when you want a balance between precision and recall, especially in imbalanced datasets.      |\n| **Support**   | Number of actual occurrences of each class in the dataset.                  | Shows how many samples of each class were present in the test set — helps interpret other metrics.   |\n","metadata":{}},{"cell_type":"code","source":"print(\"Evaluating the LSTM Model on the Test Set...\")\nloss,accuracy=model.evaluate(X_test_reshaped,y_test,verbose=0)\n\nprint(f\"Test Loss: {loss:.4f}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")\nprint(\"\\n\")\n\ny_pred_probs=model.predict(X_test_reshaped) #shape:(num_samples,num_classes)\ny_pred_classes=np.argmax(y_pred_probs,axis=1) #index of highest predicted probability\ny_true_class=np.argmax(y_test,axis=1)\n\nprint(\"Classification Report on Test Set (LSTM):\")\ntarget_names_for_report=label_encoder.inverse_transform(np.arange(num_classes))\nprint(classification_report(y_true_class,y_pred_classes,target_names=target_names_for_report))\nprint(\"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:17:10.924390Z","iopub.execute_input":"2025-07-05T16:17:10.924662Z","iopub.status.idle":"2025-07-05T16:17:12.364323Z","shell.execute_reply.started":"2025-07-05T16:17:10.924644Z","shell.execute_reply":"2025-07-05T16:17:12.363569Z"}},"outputs":[{"name":"stdout","text":"Evaluating the LSTM Model on the Test Set...\nTest Loss: nan\nTest Accuracy: 0.0112\n\n\n\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\nClassification Report on Test Set (LSTM):\n                                           precision    recall  f1-score   support\n\n                  Hand at target location       0.02      1.00      0.03         7\n            Moves hand to target location       0.00      0.00      0.00       431\n                         Performs gesture       0.00      0.00      0.00         3\nRelaxes and moves hand to target location       0.00      0.00      0.00         5\n\n                                 accuracy                           0.02       446\n                                macro avg       0.00      0.25      0.01       446\n                             weighted avg       0.00      0.02      0.00       446\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"markdown","source":"This code block performs real-time prediction of a behavior class from the latest window of sensor data using a trained LSTM model. It first checks if the DataFrame contains enough rows to simulate a full window (based on a defined `window_size`). If sufficient data exists, it extracts the last `window_size` rows as the input segment and computes 12 statistical features per expected sensor column, padding with zeros if any are missing. The resulting feature vector is validated for correct dimensionality, scaled using the same `StandardScaler` used during training, and reshaped to match the LSTM input format. The model then predicts class probabilities, selects the class with the highest probability, and decodes it into its original label using the label encoder. If the predicted class is not in a list of target behaviors, it is reclassified as `'non_target'`. The predicted behavior is printed; if data is insufficient or feature extraction fails, appropriate warnings are displayed instead.\n","metadata":{}},{"cell_type":"code","source":"print(\"Making Predictions on New Data (for a single new window)...\")\n\nif len(df) >= window_size:\n    \n    new_sensor_data_for_prediction=df.iloc[len(df) - window_size :] #Takes last window\n    new_features_for_prediction=[]\n   \n    if len(new_sensor_data_for_prediction) == window_size:\n        \n        current_prediction_features = []\n        \n        for col in ALL_EXPECTED_SENSOR_COLUMNS:\n            \n            if col in new_sensor_data_for_prediction.columns:\n                current_prediction_features.extend(extract_sensor_features(new_sensor_data_for_prediction[col]))\n            else:\n                current_prediction_features.extend([0.0] * 12)\n                                                   \n        if len(current_prediction_features) == TOTAL_FEATURE_DIMENSION:\n             new_features_for_prediction.append(current_prediction_features)\n            \n        else:\n            print(f\"Warning: Prediction feature dimension mismatch. Expected {TOTAL_FEATURE_DIMENSION}, got {len(current_prediction_features)}. Skipping.\")\n               \n    if new_features_for_prediction:\n        \n        X_new_prediction_scaled = scaler.transform(np.array(new_features_for_prediction))\n        X_new_prediction_reshaped = X_new_prediction_scaled.reshape(1, timesteps, input_features)\n\n        predicted_probs = model.predict(X_new_prediction_reshaped)\n        predicted_class_index = np.argmax(predicted_probs, axis=1)\n        predicted_behavior = label_encoder.inverse_transform(predicted_class_index)\n        \n        # Apply contest-specific mapping for single prediction\n        if predicted_behavior[0] not in target_behaviors:\n            predicted_behavior[0] = 'non_target'\n\n        print(f\"Predicted behavior for a new window of data: {predicted_behavior[0]}\")\n    else:\n        print(\"Could not generate features for prediction (window size mismatch or other issue).\")\nelse:\n    print(\"Not enough total data samples to simulate a 'new' window for prediction.\")\nprint(\"\\n\")\n\n     \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:18:16.237849Z","iopub.execute_input":"2025-07-05T16:18:16.238407Z","iopub.status.idle":"2025-07-05T16:18:16.672228Z","shell.execute_reply.started":"2025-07-05T16:18:16.238384Z","shell.execute_reply":"2025-07-05T16:18:16.671495Z"}},"outputs":[{"name":"stdout","text":"Making Predictions on New Data (for a single new window)...\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\nPredicted behavior for a new window of data: non_target\n\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"predicted_behavior_names_full = label_encoder.inverse_transform(y_pred_classes)\n\nfinal_submission_gestures = []\nfor behavior_name in predicted_behavior_names_full:\n    if behavior_name in target_behaviors:\n        final_submission_gestures.append(behavior_name)\n    else:\n        final_submission_gestures.append('non_target')\n\nsubmission_df=pd.DataFrame({\n    'sequence_id':window_ids_test,\n    'gesture': final_submission_gestures\n})\n\nsubmission_df=submission_df.sort_values(by='sequence_id').reset_index(drop=True)\n\nsubmission_file_name='submission_predictions_contest.csv'\n\nsubmission_df.to_csv(submission_file_name,index=False)\n\nprint(f\"Submission file '{submission_file_name}' created successfully.\" )\nprint(\"Sample of submission file head:\")\nprint(submission_df.head())\nprint(\"\\n\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T16:18:31.460748Z","iopub.execute_input":"2025-07-05T16:18:31.461030Z","iopub.status.idle":"2025-07-05T16:18:31.476834Z","shell.execute_reply.started":"2025-07-05T16:18:31.461010Z","shell.execute_reply":"2025-07-05T16:18:31.476152Z"}},"outputs":[{"name":"stdout","text":"Submission file 'submission_predictions_contest.csv' created successfully.\nSample of submission file head:\n   sequence_id     gesture\n0          325  non_target\n1         1550  non_target\n2         1825  non_target\n3         2850  non_target\n4         3625  non_target\n\n\n","output_type":"stream"}],"execution_count":20}]}